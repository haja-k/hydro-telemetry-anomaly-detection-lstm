{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as md\n",
    "from matplotlib import pyplot as plt\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "import scipy\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca96ae",
   "metadata": {},
   "source": [
    "### Defining Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_location = \"Roban\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc20fd17",
   "metadata": {},
   "source": [
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a87447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(filename, water_name, time_name):\n",
    "    '''\n",
    "    - read in the timestamp and waterlevel;\n",
    "    - select those waterlevel!=nan\n",
    "    - drop duplicates timestamps & waterlevel and keep the last\n",
    "    - set the 'timestamp' column into DatetimeIndex and set as index and sort it (timestamp must be monotronic)\n",
    "    '''\n",
    "    df = pd.read_csv(filename,usecols=[time_name, water_name])\n",
    "    df_new = df[df[water_name].notna()]\n",
    "    print(\"after dropping na\" + str(df_new.shape))\n",
    "    \n",
    "    '''\n",
    "    - there are duplicates in timestamps. keep the last\n",
    "    '''\n",
    "    df_new = df_new.drop_duplicates(subset=time_name, keep='last', ignore_index=True)\n",
    "    print(\"after dropping dupes\" + str(df_new.shape))\n",
    "    \n",
    "    df_new[time_name] = pd.DatetimeIndex(df_new[time_name], dayfirst=True)\n",
    "    df_new = df_new.set_index(time_name)\n",
    "    df_new = df_new.sort_index()\n",
    "    print(\"original size: \", str(df.shape))\n",
    "    print(\"after sort index: \", str(df_new.shape))\n",
    "    \n",
    "    '''\n",
    "    - change timestamp from \"date\" format to \"string format\" \n",
    "    '''\n",
    "    timestamp = df_new[water_name].index.strftime(\"%D-M%-Y%\")\n",
    "    waterlevel = df_new[water_name].values\n",
    "    print(timestamp.shape)\n",
    "    #plotOriGraph(df_new,timestamp,waterlevel,None,\"Original\")\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a185e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveToExcelFile(df, station_location, time_name, water_name, filename):\n",
    "    directory = 'cleaned/' + station_location + \"/\"\n",
    "    filename = directory+filename+\"_result.csv\"\n",
    "    if not os.path.exists( directory):\n",
    "        os.makedirs( directory)\n",
    "    df = df.rename_axis(\"timestamp\")\n",
    "    df=df.rename(columns={time_name:\"timestamp\",water_name:\"waterlevel\"})\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5ccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotOriGraph(df_new,timestamp,waterlevel,waterlevel_flat,title):\n",
    "    fig = (px.scatter(x=timestamp, y=waterlevel).update_traces(mode='markers+lines'))\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_layout(\n",
    "        {\n",
    "            \"title\":title,\n",
    "            \"xaxis\":{\n",
    "                \"title\":\"timestamp\"\n",
    "            },\n",
    "            \"yaxis\":{\n",
    "                \"title\":\"waterlevel\"\n",
    "            }\n",
    "        })\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33897d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spikeWithThreshold(df_waterlevel, TP='T'):\n",
    "    if TP == \"T\" or TP == \"t\":\n",
    "        threshold = 0.6\n",
    "    elif TP == \"NT\" or TP == \"Nt\" or TP == \"nt\":\n",
    "        threshold = 0.3\n",
    "        \n",
    "    value = np.array(df_waterlevel)\n",
    "    diff_list = []\n",
    "    anolist = []\n",
    "    threshold1 = threshold\n",
    "    threshold2 =threshold*-1\n",
    "    anoboo = abs(value) > abs(value) + threshold1 # default all entities in the array to false\n",
    "    \n",
    "    for i in range (1, len(value)):         \n",
    "        diff_list.append(value[i] - value[i-1])\n",
    "\n",
    "    for i in range (0, len(diff_list)):                      \n",
    "        if diff_list[i] >= threshold1 or diff_list[i] <= threshold2:\n",
    "            anolist.append(df_waterlevel.index[i+1])\n",
    "            anoboo[i+1] = True # set to true if spike detected (difference > threshold)\n",
    "\n",
    "    anono = anoboo.copy()\n",
    "    # note : index of anoboo[i] = diff_list[i-1]\n",
    "    for i in range (0, len(anoboo)):\n",
    "        if (i != 0) and (i+1 < len(anoboo)):\n",
    "            if anoboo[i] == True and anoboo[i-1] == True:\n",
    "                # if i spike up and i+1 spike down, then i+1 is not a spike\n",
    "                # eg : i-1 = 0.5, i = 2.3, i+1 = 0.6, i is spike, i+1 is not a spike\n",
    "                if (diff_list[i-1] > 0 and diff_list[i-2] < 0) or (diff_list[i-1] < 0 and diff_list[i-2] > 0):\n",
    "                    anoboo[i] = False\n",
    "\n",
    "                # if i spike up and i+1 spike another up (difference between [(i and i+1) > 0.6] and [(i-1 and i+1 > 1.2)])\n",
    "                # eg: i-1 = 0.1, i = 0.73 (>0.6), i+1 = 1.5 (>0.6), so i is not a spike, i+1 is spike\n",
    "                elif (diff_list[i-1] > 0 and diff_list[i-2] > 0) or (diff_list[i-1] < 0 and diff_list[i-2] < 0):\n",
    "                    anoboo[i-1] = False\n",
    "\n",
    "            # if i is spike and i+1 is within the range of 0.59 with i (i+1 = i +- threshold), i is not a spike\n",
    "            # eg : i-1 = 0.6, i = 4.5, i+1 = 4.6, i is not a spike, i and i+1 is a trend (detect only 1 sharp point spike as spike, else is trend)\n",
    "            # can write as (abs(diff_list[i-1]) > 0) and (abs(diff_list[i-1]) < threshold1) and ***anoboo[i] == True***:\n",
    "            elif (abs(diff_list[i-1]) > 0) and (abs(diff_list[i-1]) < threshold1) and (abs(diff_list[i-2]) > threshold1):\n",
    "                anoboo[i-1] = False\n",
    "\n",
    "    return anoboo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0fbc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_filtered(signal, threshold=3.5):\n",
    "    signal = signal.copy()\n",
    "    peak = signal.copy()\n",
    "    difference = np.abs(signal - np.median(signal))\n",
    "    median_difference = np.median(difference)\n",
    "    if median_difference == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = 0.675*difference / float(median_difference)\n",
    "    # find the whr the peak\n",
    "    mask = s > threshold\n",
    "\n",
    "    # replace the outliers with median of the graph\n",
    "    signal[mask] = np.median(signal)\n",
    "    return signal,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36138d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotGraph(df_new, timestamp, waterlevel, waterlevel_flat, title):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scattergl(x=timestamp, y=waterlevel,\n",
    "                    mode='lines+markers',\n",
    "                    name='Original'))\n",
    "    fig.add_trace(go.Scattergl(x=timestamp, y=waterlevel_flat,\n",
    "                    mode='lines+markers',\n",
    "                    name=title))\n",
    "#     fig = px.add_line(x=timestamp,y=waterlevel_flat)\n",
    "    fig.update_xaxes(rangeslider_visible=True)\n",
    "    fig.update_layout(\n",
    "        {\n",
    "            \"title\":title,\n",
    "            \"xaxis\":{\n",
    "                \"title\":\"timestamp\"\n",
    "            },\n",
    "            \"yaxis\":{\n",
    "                \"title\":\"waterlevel\"\n",
    "            }\n",
    "        })\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillwithline(y, spiketnt, timestamp, waterlevel):\n",
    "    df_temp = pd.DataFrame()\n",
    "    df_temp['timestamp'] = timestamp\n",
    "    df_temp['waterlevel'] = waterlevel\n",
    "\n",
    "    df_raw = df_temp['waterlevel']\n",
    "    df_keep = df_raw.loc[np.where(spiketnt!=1)[0]] #find those who are normal\n",
    "\n",
    "    df_out = pd.merge(df_keep,df_raw,how='outer',left_index=True,right_index=True)\n",
    "\n",
    "    # Keep only the first column\n",
    "    s = df_out.iloc[:, 0]#.to_frame()\n",
    "    # df_temp['waterlevel'] = df_out.iloc[:, 0]\n",
    "\n",
    "    # 8. Fill missing values\n",
    "    df_complete = s.fillna(axis=0, method='ffill').fillna(axis=0,method=\"bfill\")\n",
    "    df_temp['waterlevel'] = df_complete.values\n",
    "    df_interpolate = s.interpolate()\n",
    "    df_temp['inter_waterlevel'] = df_interpolate\n",
    "    return df_temp['waterlevel'].values,df_temp['inter_waterlevel'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13568aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(test_filename, station_location, timestamp_name, waterlevel_name, scaler_filename=None, model_name=None, csv_name=None):\n",
    "    test_data = format_data(test_filename, waterlevel_name, timestamp_name)  # the one mad cannot detect\n",
    "    \n",
    "    test_data['cleaned'] = scipy.signal.medfilt(test_data[waterlevel_name], 11)\n",
    "    anomalies = spikeWithThreshold(test_data[waterlevel_name],TP=\"NT\")\n",
    "    test_data['after_checking'],test_data['inter_checking'] = fillwithline(test_data, anomalies,test_data[waterlevel_name].index, test_data[waterlevel_name].values)\n",
    "    test_data['u_medf'], anomalies = get_median_filtered(test_data[waterlevel_name].values, threshold=3)\n",
    "    anomalies_med = spikeWithThreshold(test_data['u_medf'],TP=\"NT\")\n",
    "    test_data['med_check'],test_data['med_inter_checking'] = fillwithline(test_data, anomalies_med,test_data['u_medf'].index, test_data['u_medf'].values)\n",
    "    \n",
    "    saveToExcelFile(test_data, station_location, timestamp_name, waterlevel_name, csv_name)\n",
    "    test_data.head()\n",
    "    # plotOriGraph(test_data, test_data.index, test_data['rectified'].values, None, title=\"Rectified\")\n",
    "    plotGraph(test_data,test_data.index,test_data[waterlevel_name].values,test_data['cleaned'].values,title=\"Rectified\")\n",
    "    plotGraph(test_data,test_data.index,test_data[waterlevel_name].values,test_data['after_checking'].values,title=\"Rectified\")\n",
    "    plotGraph(test_data,test_data.index,test_data[waterlevel_name].values,test_data['med_check'].values,title=\"Rectified\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857b5955",
   "metadata": {},
   "source": [
    "### Loop for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e7bb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory = '../src/dataset/' + station_location\n",
    "\n",
    "for i in range(2016,2022):\n",
    "    year = str(i)\n",
    "    csv_name = station_location + \"_\" + year\n",
    "    filename = directory + \"/\" + csv_name + \".csv\"\n",
    "    data(filename, station_location, \n",
    "         timestamp_name=\"timestamp\",\n",
    "         waterlevel_name=\"actual_reading\",\n",
    "         csv_name=csv_name\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dc93e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
